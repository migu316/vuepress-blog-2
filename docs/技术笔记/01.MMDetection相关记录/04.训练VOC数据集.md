---
title: 训练VOC数据集
date: 2021-10-10 10:31:56
permalink: /pages/11bf4a/
categories:
  - 技术笔记
  - MMDetection相关记录
tags:
  - MMDetection
---
# MMDetection训练VOC数据集

## 准备VOC数据集

数据集目录格式：

```shell
VOCdevkit
├── VOC2007
│   ├── Annotations
│   ├── JPEGImages
│   ├── ImageSets
│   │   ├── Main
│   │   │   ├── test.txt
│   │   │   ├── trainval.txt
```

## 修改配置文件

在你的配置文件中添加以下代码：

::: tip

注意将其中的数据集路径修改为你的。

:::

```python
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)

train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1000, 600),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]

# 数据集配置
dataset_type = 'VOCDataset'
data_root = '/home/lgh/mmlabTest/data/VOCdevkit/'
# classes = ('sy', 'gy', 'lk')
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=1,
    train=dict(
        type='RepeatDataset',
        times=3,
        dataset=dict(
            type=dataset_type,
            ann_file=[
                # data_root + 'VOC2007/ImageSets/Main/trainval.txt',
                # data_root + 'VOC2012/ImageSets/Main/trainval.txt'
                data_root + 'VOC2007/ImageSets/Main/trainval.txt'
            ],
            # img_prefix=[data_root + 'VOC2007/', data_root + 'VOC2012/'],
            img_prefix=[data_root + 'VOC2007/'],
            pipeline=train_pipeline)),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'VOC2007/ImageSets/Main/test.txt',
        img_prefix=data_root + 'VOC2007/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'VOC2007/ImageSets/Main/test.txt',
        img_prefix=data_root + 'VOC2007/',
        pipeline=test_pipeline))
evaluation = dict(interval=1, metric='mAP')

# checkpoint_config = dict(interval=10)
optimizer_config = dict(
    _delete_=True,
    grad_clip=dict(max_norm=35, norm_type=2))

log_config = dict(
    interval=1,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(type='TensorboardLoggerHook')
    ])

workflow = [('train', 1), ('val', 1)]
```

::: tip

配置文件中的默认学习率是8个gpu和2个img/gpu(batch size= 8*2 =  16)。根据线性缩放规则，如果您使用不同的GPU数目或img/gpu，您需要设置与batch size成比例的学习率。例如，如果4GPUs * 2 img/gpu的lr=0.01，那么16GPUs * 4 img/gpu的lr=0.08。

lr = 0.00125*batch_size

:::

## 修改一些文件

- 修改你自己的配置文件中的`num_classes`改为你自己的类别数目。

- 修改`mmdetection/mmdet/datasets/voc.py`，把CLASSES的那个tuple改为自己数据集对应的种类tuple即可。

  ```python
      # CLASSES = ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',
      #            'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',
      #            'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train',
      #            'tvmonitor')
  
      CLASSES = ('sy', 'gy', 'lk')
  ```

- 修改`mmdetection/mmdet/core/evaluation/class_names.py`，修改voc_classes数据集类别，这个关系到后面test的时候结果图中显示的类别名称。

  ```python
  # def voc_classes():
  #     return [
  #         'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',
  #         'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person',
  #         'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
  #     ]
  
  def voc_classes():
      return ['sy', 'gy', 'lk']
  ```

- 修改`/mmdetection/mmdet/datasets/xml_style.py`，将图片类型换成你的图片类型。
  ```python
      def load_annotations(self, ann_file):
        """Load annotation from XML style ann_file.

        Args:
            ann_file (str): Path of XML file.

        Returns:
            list[dict]: Annotation info from XML file.
        """

        data_infos = []
        img_ids = mmcv.list_from_file(ann_file)
        for img_id in img_ids:
            filename = f'JPEGImages/{img_id}.jpeg'
            xml_path = osp.join(self.img_prefix, 'Annotations',
                                f'{img_id}.xml')
            tree = ET.parse(xml_path)
            root = tree.getroot()
            size = root.find('size')
            width = 0
            height = 0
            if size is not None:
                width = int(size.find('width').text)
                height = int(size.find('height').text)
            else:
                img_path = osp.join(self.img_prefix, 'JPEGImages',
                                    '{}.bmp'.format(img_id))
                img = Image.open(img_path)
                width, height = img.size
            data_infos.append(
                dict(id=img_id, filename=filename, width=width, height=height))

        return data_infos
  ```

## 开始训练即可

```bash
python tools/train.py configs/cascade_rcnn/cascade_rcnn_x101_64x4d_fpn_20e_coco.py
```

